Notes about the school analysis

12/8/17
I having a really hard time treating the grade values as ordinal. Agresti p. 195 talks about an approach to test for conditional independence between K strata using the CMH test statistic. However, the CMH test statistic is only defined for 2 x 2 x K tables. With three schools and 5 grades we would have a 3 x 5 x K table. There is a generalized CMH statistic that he uses. I do not understand how to calculate this test statistic. If we can figure out the generalized CMH test, we can set K = 1 and do a subject by subject analysis or set K = number of courses and account for all grades for schools.
--> An email was sent to Terhorst about my inability to understand this generalized test statistic.

I went on with the analysis not treating the grade values as ordinal. Most of the 0's in the counts are in the 1 and 2 grade value marks. This shows a warning that the chi square test for independence might not be exact. I ran a test for independence for the three schools over each subject. All p-values were 0. There is no evidence that of an association between school and the grade distribution. All the schools are the same. I also ran the analysis excluding the 1 and 2 grade values, it made no difference. While uninteresting, it shows that the schools are handing out grades in the same way.
--> Possible add more schools? The analysis is very quick.

Moved on to try and fit a mixed effect model. The response variable is if the student passed (grade value 4 or 5) coded as 0 or if they failed (grade value 1-3) coded as 1. There is some concern because there are barely any 1 and 2's. So even by including 3, the failed group is much smaller than the pass group. First tried to fit a mixed effect model with school being the random intercept. It takes a really long time. Could we run this on a server?
--> A mixed effect model with the school as a random slope and the courses as a fixed effect. The model was taking a really long time, so I fit a model only on 1/2 of the data. This still takes a while. I could run a bigger model overnight, however, after trying the model with 1%, 10% 25% and 33% I get very similar results. The sigma-hat value of 0.474. In magnitude this value is about in the middle of our fixed effects variables. From class we talked about a large standard deviation would indicate a large dependence in school. However, because the standard deviation is kind of small, there does not seem to be a large dependence on which school.

We could also start looking at the fixed effects. Which subjects have a higher odds of failing? The base subject is Biology. So for example, a student has a exp(0.76218) = 2.14x times higher odds of failing math than biology... I think this how you interpret it.

Random effects:
 Groups         Name        Variance Std.Dev.
 institution_id (Intercept) 0.2246   0.4739  
Number of obs: 176928, groups:  institution_id, 3

Fixed effects:
                                            Estimate Std. Error z value Pr(>|z|)    
(Intercept)                                 -0.90905    0.11689   -7.78 7.42e-15 ***
factor(course_subject_EN)Chemistry           0.52303    0.02390   21.89  < 2e-16 ***
factor(course_subject_EN)English             0.27987    0.02422   11.56  < 2e-16 ***
factor(course_subject_EN)Estonian Language   0.01310    0.02519    0.52 0.602989    
factor(course_subject_EN)Geography          -0.07615    0.02651   -2.87 0.004081 ** 
factor(course_subject_EN)History            -0.08354    0.02496   -3.35 0.000818 ***
factor(course_subject_EN)Literature         -0.24713    0.02562   -9.65  < 2e-16 ***
factor(course_subject_EN)Mathematics         0.76218    0.02394   31.84  < 2e-16 ***
factor(course_subject_EN)Music              -0.97114    0.03028  -32.07  < 2e-16 ***
factor(course_subject_EN)Physical Education -1.63191    0.03455  -47.23  < 2e-16 ***
factor(course_subject_EN)Physics             0.42480    0.02427   17.50  < 2e-16 ***
factor(course_subject_EN)Russian Language    0.62398    0.02406   25.94  < 2e-16 ***


--> The other model that I tried to run was a mixed effect model where the course was considered random as well. So there would be a random slope because of the school and a random intercept by the course. However, I am having a lot of problems. The model isn't converging or something. More work on that.



**********
* Idea: Do we have any school information? Private or Public? Size? % of students with certain reading level? To fit a hierarchical model we would need a second-level model that is all about the schools. I think this is a very natural place to use this type of model if we have this information. Check lecture 10 page 11 for notes.
*********

12/10/17
We aggregated across terms in the first model. This was maybe not a good idea. This time we are going to take the first term for each school only... Did that and still all the p-values are 0.

We then when and fit the model that we did before. Now that we have less data, we can fit the model on all the data. We see that English and Estonian are not sig. Base case is still Biology.

The standard deviation is 0.5532. It is bigger than half of the coefficients but smaller than half of them too. So we still do not think that there is much variation in schools.

Random effects:
 Groups         Name        Variance Std.Dev.
 institution_id (Intercept) 0.3061   0.5532  
Number of obs: 189504, groups:  institution_id, 3

Fixed effects:
                                             Estimate Std. Error z value Pr(>|z|)    
(Intercept)                                 -0.947045   0.189386   -5.00 5.71e-07 ***
factor(course_subject_EN)Chemistry           0.177413   0.022011    8.06 7.61e-16 ***
factor(course_subject_EN)English             0.013934   0.022943    0.61    0.544    
factor(course_subject_EN)Estonian Language  -0.002969   0.022923   -0.13    0.897    
factor(course_subject_EN)History            -0.202058   0.023200   -8.71  < 2e-16 ***
factor(course_subject_EN)Literature         -0.358965   0.023639  -15.19  < 2e-16 ***
factor(course_subject_EN)Mathematics         0.731476   0.021699   33.71  < 2e-16 ***
factor(course_subject_EN)Physical Education -1.884896   0.033947  -55.53  < 2e-16 ***
factor(course_subject_EN)Physics             0.261881   0.022430   11.68  < 2e-16 ***
factor(course_subject_EN)Russian Language    0.639143   0.021913   29.17  < 2e-16 ***


Need sure how to interpret a model where there is also a random effects on the course.

When only running the model on 1% of the data I get these weird warnings:
Warning messages:
1: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
2: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
  failure to converge in 10000 evaluations
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00368835 (tol = 0.001, component 1)

Random effects:
 Groups         Name                                Variance  Std.Dev. Corr                               
 institution_id (Intercept)                         0.1924400 0.43868                                     
                course_subject_ENChemistry          0.0402602 0.20065   0.37                              
                course_subject_ENEnglish            0.0004997 0.02235   0.98  0.55                        
                course_subject_ENEstonian Language  0.0279371 0.16714  -0.39 -1.00 -0.57                  
                course_subject_ENHistory            0.1565991 0.39573   0.39  1.00  0.56 -1.00            
                course_subject_ENLiterature         0.0029072 0.05392   0.14 -0.87 -0.06  0.85 -0.86      
                course_subject_ENMathematics        0.0415641 0.20387   0.64  0.95  0.78 -0.96  0.96 -0.67
                course_subject_ENPhysical Education 0.0517345 0.22745   0.26 -0.80  0.06  0.79 -0.79  0.99 -0.58
                course_subject_ENPhysics            1.2225775 1.10570   0.75  0.89  0.87 -0.90  0.90 -0.55 0.99 -0.45
                course_subject_ENRussian Language   0.1875733 0.43310   0.10  0.96  0.30 -0.96  0.96 -0.97 0.83 -0.94  0.73
Number of obs: 1808, groups:  institution_id, 3

Fixed effects:
                                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)                         -0.97212    0.31007  -3.135  0.00172 ** 
course_subject_ENChemistry           0.22402    0.26841   0.835  0.40393    
course_subject_ENEnglish             0.01242    0.25524   0.049  0.96118    
course_subject_ENEstonian Language  -0.01726    0.27043  -0.064  0.94911    
course_subject_ENHistory            -0.19359    0.34524  -0.561  0.57497    
course_subject_ENLiterature         -0.36863    0.26525  -1.390  0.16461    
course_subject_ENMathematics         0.77208    0.26438   2.920  0.00350 ** 
course_subject_ENPhysical Education -2.06506    0.46236  -4.466 7.96e-06 ***
course_subject_ENPhysics             0.04158    0.70069   0.059  0.95268    
course_subject_ENRussian Language    0.70853    0.34560   2.050  0.04035 *